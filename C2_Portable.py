import sys
import subprocess
import os
import datetime
import unicodedata
import base64
import threading
import requests
import tempfile
import time
import pygame
import sounddevice as sd
import numpy as np
import io
import wave
from anthropic import Anthropic
from tavily import TavilyClient
from dotenv import load_dotenv
from jamo import jamo_to_hcj
from google import genai
from PIL import Image

# 1. í™˜ê²½ ì„¤ì • ë° API ë¡œë“œ
load_dotenv()
anthropic_client = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
tavily = TavilyClient(api_key=os.getenv("TAVILY_API_KEY"))
gemini_client = genai.Client(api_key=os.getenv("GOOGLE_API_KEY"))
ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

AI_NAME = "Orion"
PROFILE_FILE = "user_profile.txt"
TEMP_IMAGE = "temp_capture.png"
CLAUDE_MODEL = "claude-sonnet-4-5-20250929"
MUSIC_FOLDER = "Music"

# Wake Word ì„¤ì • (ë‹¤ì–‘í•œ ë°œìŒ ë³€í˜•)
WAKE_WORDS = [
    "hey orion", "hey orian", "hey oreon", "hey orianne",
    "a orion", "a orian", "hey oryan", "hey aurion",
    "orion", "orian", "hey orient", "hey o'brien"
]

# ElevenLabs ì„¤ì •
ELEVENLABS_VOICE_ID = "QYrOVogqhHWUzdZFXf0E"
ELEVENLABS_API_URL = f"https://api.elevenlabs.io/v1/text-to-speech/{ELEVENLABS_VOICE_ID}"

# ì˜¤ë””ì˜¤ ì„¤ì •
SAMPLE_RATE = 16000
CHANNELS = 1


# --- [ìŒì•… í”Œë ˆì´ì–´] ---
class MusicPlayer:
    def __init__(self):
        pygame.mixer.init()
        self.is_playing = False
        self.current_song = None
        self.normal_volume = 0.2
        self.ducked_volume = 0.05
    
    def duck(self):
        if self.is_playing:
            pygame.mixer.music.set_volume(self.ducked_volume)
    
    def unduck(self):
        if self.is_playing:
            pygame.mixer.music.set_volume(self.normal_volume)
    
    def play(self, song_name):
        self.stop()
        filename = song_name.strip().replace(" ", "_")
        if not filename.lower().endswith(".mp3"):
            filename += ".mp3"
        
        filepath = os.path.join(MUSIC_FOLDER, filename)
        
        if not os.path.exists(filepath):
            if os.path.exists(MUSIC_FOLDER):
                for f in os.listdir(MUSIC_FOLDER):
                    if f.lower() == filename.lower():
                        filepath = os.path.join(MUSIC_FOLDER, f)
                        break
                else:
                    return False
            else:
                return False
        
        try:
            pygame.mixer.music.load(filepath)
            pygame.mixer.music.set_volume(self.normal_volume)
            pygame.mixer.music.play(loops=-1)
            self.is_playing = True
            self.current_song = song_name
            return True
        except:
            return False
    
    def stop(self):
        if self.is_playing:
            pygame.mixer.music.stop()
        self.is_playing = False
        self.current_song = None


# --- [ë©”ì¸ ì˜¤ë¦¬ì˜¨ ë´‡ - íœ´ëŒ€ìš© ìŒì„± ì „ìš©] ---
class OrionPortable:
    def __init__(self):
        self.short_term_memory = []
        self.music_player = MusicPlayer()
        self.is_running = True
        self.is_speaking = False
        
        # ì˜¤ë””ì˜¤ ì„¤ì •
        self.sample_rate = 16000
        self.channels = 1
        self.energy_threshold = 0.01  # ë§¤ìš° ë‚®ì€ ì„ê³„ê°’
        self.silence_duration = 1.5
        
        self.load_personal_profile()
        
    def load_personal_profile(self):
        extra_info = ""
        if os.path.exists(PROFILE_FILE):
            with open(PROFILE_FILE, "r", encoding="utf-8") as f:
                extra_info = f.read()
        
        self.system_prompt = (
            f"ë‹¹ì‹ ì€ ê±´í¬ì˜ ì „ìš© AI ë¹„ì„œ '{AI_NAME}'ì´ì•¼.\n"
            f"[ê±´í¬ ì •ë³´]\n{extra_info}\n"
            "í•µì‹¬ ì§€ì¹¨:\n"
            "1. ë¬´ì¡°ê±´ 'ì¡´ëŒ“ë§'ë¡œ ë§ˆì¹˜ ì˜í™” ì•„ì´ì–¸ë§¨ì— ë‚˜ì˜¤ëŠ” ìë¹„ìŠ¤ì²˜ëŸ¼ ì°¨ë¶„í•˜ê³  ë˜‘ë˜‘í•˜ê²Œ ë§í•´ì¤˜.\n"
            "2. ë‹µë³€ì€ ë¬´ì¡°ê±´ 'í•œ ë¬¸ì¥'ìœ¼ë¡œ ì•„ì£¼ ì§§ê³  í•µì‹¬ë§Œ ë§í•´.\n"
            "3. ì´ì „ ëŒ€í™” ë§¥ë½ì„ ê¸°ì–µí•´ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ê°€ì¤˜.\n"
            "4. ê±´í¬ ëŒ€ì‹  sir ì´ë¼ê³  ë§í•´."
        )

    def notify(self, msg):
        """macOS ì•Œë¦¼"""
        try:
            subprocess.run(["osascript", "-e", 
                f'display notification "{msg.replace(chr(34), chr(39))}" with title "{AI_NAME}"'],
                capture_output=True)
        except:
            pass

    def speak(self, text):
        """ElevenLabs TTS (ë™ê¸°ì‹)"""
        self.is_speaking = True
        try:
            self.music_player.duck()
            
            english_text = self.translate_to_english(text)
            print(f"ğŸ”Š [{AI_NAME}]: {english_text}")
            
            headers = {
                "Accept": "audio/mpeg",
                "Content-Type": "application/json",
                "xi-api-key": ELEVENLABS_API_KEY
            }
            
            data = {
                "text": english_text,
                "model_id": "eleven_turbo_v2_5",
                "voice_settings": {
                    "stability": 0.5,
                    "similarity_boost": 0.75,
                    "style": 0.3,
                    "use_speaker_boost": True
                }
            }
            
            response = requests.post(ELEVENLABS_API_URL, json=data, headers=headers)
            
            if response.status_code == 200:
                with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as f:
                    f.write(response.content)
                    temp_path = f.name
                
                subprocess.run(["afplay", temp_path], capture_output=True)
                os.remove(temp_path)
                
        except Exception as e:
            print(f"[TTS Error] {e}")
        finally:
            self.music_player.unduck()
            self.is_speaking = False

    def translate_to_english(self, korean_text):
        """í•œêµ­ì–´ â†’ ì˜ì–´ ë²ˆì—­"""
        try:
            response = anthropic_client.messages.create(
                model=CLAUDE_MODEL,
                max_tokens=200,
                messages=[{
                    "role": "user", 
                    "content": f"Translate to natural English. 'ê±´í¬' = 'Gun-hee'. Output translation only:\n\n{korean_text}"
                }]
            )
            result = response.content[0].text.strip()
            for old in ["Geonhee", "Gunhee", "Keonhee", "ê±´í¬"]:
                result = result.replace(old, "Gun-hee")
            return result
        except:
            return korean_text

    def record_audio(self, duration=4):
        """ê³ ì • ì‹œê°„ ë™ì•ˆ ë…¹ìŒ (ê°„ë‹¨í•œ ë°©ì‹)"""
        print(f"ğŸ¤ ë…¹ìŒ ì¤‘... ({duration}ì´ˆ)")
        
        try:
            # ê³ ì • ì‹œê°„ ë…¹ìŒ
            audio_data = sd.rec(
                int(duration * self.sample_rate),
                samplerate=self.sample_rate,
                channels=self.channels,
                dtype='float32'
            )
            sd.wait()  # ë…¹ìŒ ì™„ë£Œ ëŒ€ê¸°
            
            # ë³¼ë¥¨ ì²´í¬
            volume = np.sqrt(np.mean(audio_data**2))
            print(f"ğŸ“Š ë³¼ë¥¨: {volume:.6f}")
            
            if volume < 0.001:
                print("ğŸ”‡ ì†Œë¦¬ ì—†ìŒ")
                return None
            
            return audio_data
            
        except Exception as e:
            print(f"ë…¹ìŒ ì—ëŸ¬: {e}")
            return None

    def to_wav_bytes(self, audio_data):
        """numpy ë°°ì—´ì„ WAV ë°”ì´íŠ¸ë¡œ ë³€í™˜"""
        buffer = io.BytesIO()
        with wave.open(buffer, 'wb') as wf:
            wf.setnchannels(self.channels)
            wf.setsampwidth(2)  # 16-bit
            wf.setframerate(self.sample_rate)
            # float32 -> int16 ë³€í™˜
            audio_int16 = (audio_data * 32767).astype(np.int16)
            wf.writeframes(audio_int16.tobytes())
        buffer.seek(0)
        return buffer.read()

    def transcribe(self, audio_data):
        """ìŒì„± â†’ í…ìŠ¤íŠ¸ (Whisper API)"""
        if not OPENAI_API_KEY:
            print("âš ï¸ OPENAI_API_KEY ì—†ìŒ!")
            return None
        
        try:
            wav_bytes = self.to_wav_bytes(audio_data)
            
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
                f.write(wav_bytes)
                temp_path = f.name
            
            print(f"ğŸ“¤ Whisper APIë¡œ ì „ì†¡ ì¤‘... ({len(wav_bytes)} bytes)")
            
            with open(temp_path, "rb") as audio_file:
                response = requests.post(
                    "https://api.openai.com/v1/audio/transcriptions",
                    headers={"Authorization": f"Bearer {OPENAI_API_KEY}"},
                    files={"file": audio_file},
                    data={"model": "whisper-1", "language": "en", "prompt": "Hey Orion"}
                )
            os.remove(temp_path)
            
            if response.status_code == 200:
                text = response.json().get("text", "")
                print(f"ğŸ“¥ Whisper ê²°ê³¼: '{text}'")
                return text
            else:
                print(f"Whisper ì—ëŸ¬: {response.status_code} - {response.text}")
                return None
        except Exception as e:
            print(f"Transcribe ì—ëŸ¬: {e}")
            return None

    def get_ai_response(self, user_text):
        """AI ì‘ë‹µ ìƒì„±"""
        try:
            user_text = unicodedata.normalize('NFC', user_text)
            now = datetime.datetime.now()
            time_info = f"[í˜„ì¬: {now.strftime('%Y-%m-%d %H:%M')}]"
            
            search_keywords = ["ë‚ ì”¨", "ë‰´ìŠ¤", "ì˜¤ëŠ˜", "í˜„ì¬", "ì§€ê¸ˆ", "weather", "news", "today"]
            context = ""
            
            if any(kw in user_text.lower() for kw in search_keywords):
                try:
                    search_res = anthropic_client.messages.create(
                        model=CLAUDE_MODEL, max_tokens=50,
                        messages=[{"role": "user", "content": f"'{user_text}' ê²€ìƒ‰ì–´ ì˜ì–´ë¡œ í•˜ë‚˜ë§Œ: "}]
                    )
                    query = search_res.content[0].text.strip()
                    res = tavily.search(query=query, search_depth="basic", max_results=2)
                    context = "\n[ê²€ìƒ‰ê²°ê³¼]: " + " ".join([r['content'][:200] for r in res['results']])
                except:
                    pass

            messages = list(self.short_term_memory)
            messages.append({"role": "user", "content": f"{time_info} {user_text} {context}"})

            response = anthropic_client.messages.create(
                model=CLAUDE_MODEL,
                max_tokens=150,
                system=self.system_prompt,
                messages=messages
            )
            answer = response.content[0].text.strip()
            
            self.short_term_memory.append({"role": "user", "content": user_text})
            self.short_term_memory.append({"role": "assistant", "content": answer})
            if len(self.short_term_memory) > 10:
                self.short_term_memory = self.short_term_memory[-10:]
            
            return answer
        except Exception as e:
            return f"ì ì‹œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def process_command(self, text):
        """ìŒì„± ëª…ë ¹ ì²˜ë¦¬"""
        cmd = text.lower()
        
        # ì¢…ë£Œ
        if any(w in cmd for w in ["goodbye", "shut down", "turn off", "stop listening", "ì¢…ë£Œ"]):
            self.speak("ì˜¤ë¦¬ì˜¨ C2 ì‘ë™ì„ ì¤‘ì§€í•˜ê² ìŠµë‹ˆë‹¤. ì•ˆë…•íˆ ê°€ì„¸ìš”.")
            self.is_running = False
            return
        
        # ìŒì•… ì¬ìƒ
        if any(w in cmd for w in ["play ", "í”Œë ˆì´", "í‹€ì–´"]):
            for kw in ["play ", "í”Œë ˆì´ ", "í‹€ì–´ ", "í‹€ì–´ì¤˜ "]:
                if kw in cmd:
                    song = text[cmd.find(kw) + len(kw):].strip()
                    if song:
                        if self.music_player.play(song):
                            self.speak(f"{song} ì¬ìƒí•˜ê² ìŠµë‹ˆë‹¤.")
                        else:
                            self.speak(f"{song} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        return
        
        # ìŒì•… ì¤‘ì§€
        if any(w in cmd for w in ["stop music", "stop song", "ìŒì•… ì¤‘ì§€", "ìŒì•… êº¼"]):
            self.music_player.stop()
            self.speak("ìŒì•…ì„ ì¤‘ì§€í–ˆìŠµë‹ˆë‹¤.")
            return
        
        # ë³¼ë¥¨ ì¡°ì ˆ
        if "volume up" in cmd or "ë³¼ë¥¨ ì—…" in cmd:
            self.music_player.normal_volume = min(1.0, self.music_player.normal_volume + 0.1)
            pygame.mixer.music.set_volume(self.music_player.normal_volume)
            self.speak(f"ë³¼ë¥¨ì„ ë†’ì˜€ìŠµë‹ˆë‹¤.")
            return
        
        if "volume down" in cmd or "ë³¼ë¥¨ ë‹¤ìš´" in cmd:
            self.music_player.normal_volume = max(0.0, self.music_player.normal_volume - 0.1)
            pygame.mixer.music.set_volume(self.music_player.normal_volume)
            self.speak(f"ë³¼ë¥¨ì„ ë‚®ì·„ìŠµë‹ˆë‹¤.")
            return
        
        # ì¼ë°˜ ëŒ€í™”
        answer = self.get_ai_response(text)
        self.notify(answer)
        self.speak(answer)

    def extract_command(self, text):
        """Wake word ë’¤ì˜ ëª…ë ¹ ì¶”ì¶œ"""
        text_lower = text.lower()
        for wake in WAKE_WORDS:
            if wake in text_lower:
                idx = text_lower.find(wake) + len(wake)
                cmd = text[idx:].strip()
                cmd = cmd.lstrip(',').lstrip()
                if len(cmd) > 2:
                    return cmd
        return None

    def run(self):
        """ë©”ì¸ ë£¨í”„"""
        print(f"\n{'='*50}")
        print(f"  ğŸ§ {AI_NAME} C2 Portable - ìŒì„± ì „ìš© ëª¨ë“œ")
        print(f"{'='*50}")
        print(f"âœ… Whisper API: {'í™œì„±í™”' if OPENAI_API_KEY else 'ë¹„í™œì„±í™”'}")
        print(f"âœ… Sounddevice ì˜¤ë””ì˜¤ ì‚¬ìš©")
        print(f"âœ… 'Hey Orion'ì´ë¼ê³  ë§í•˜ì„¸ìš”!")
        print(f"âœ… ì¢…ë£Œ: 'Hey Orion, goodbye' ë˜ëŠ” Ctrl+C")
        print(f"{'='*50}\n")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ì˜¤ë””ì˜¤ ì¥ì¹˜ ì¶œë ¥
        print("ğŸ¤ ì˜¤ë””ì˜¤ ì¥ì¹˜:")
        print(sd.query_devices())
        print(f"\nğŸ¤ ê¸°ë³¸ ì…ë ¥ ì¥ì¹˜: {sd.default.device[0]}")
        print()
        
        self.notify("ì˜¤ë¦¬ì˜¨ C2 ì‹œì‘ë¨! Hey Orionì´ë¼ê³  ë§í•˜ì„¸ìš”.")
        self.speak("ì˜¤ë¦¬ì˜¨ C2 ê°€ë™ë˜ì—ˆìŠµë‹ˆë‹¤. ì–¸ì œë“  ë¶ˆëŸ¬ì£¼ì„¸ìš”.")
        
        while self.is_running:
            try:
                # TTS ì¤‘ì´ë©´ ìŠ¤í‚µ
                if self.is_speaking:
                    time.sleep(0.1)
                    continue
                
                # 4ì´ˆê°„ ë…¹ìŒ
                audio_data = self.record_audio(duration=4)
                
                if audio_data is None:
                    continue
                
                # ìŒì„± â†’ í…ìŠ¤íŠ¸
                text = self.transcribe(audio_data)
                
                if not text or len(text.strip()) < 2:
                    continue
                
                print(f"ğŸ‘‚ ë“¤ë¦¼: '{text}'")
                
                # Wake word ì²´í¬
                text_lower = text.lower()
                wake_detected = any(wake in text_lower for wake in WAKE_WORDS)
                
                if wake_detected:
                    print("âœ¨ Wake word ê°ì§€!")
                    
                    command = self.extract_command(text)
                    
                    if command:
                        print(f"ğŸ“ ëª…ë ¹: '{command}'")
                        self.process_command(command)
                    else:
                        self.speak("ë„¤, ë§ì”€í•˜ì„¸ìš”.")
                        print("â³ ëª…ë ¹ ëŒ€ê¸° ì¤‘...")
                        
                        # ë” ê¸´ ì‹œê°„ ë…¹ìŒ
                        audio_data2 = self.record_audio(duration=8)
                        if audio_data2 is not None:
                            command = self.transcribe(audio_data2)
                            if command:
                                print(f"ğŸ“ ëª…ë ¹: '{command}'")
                                self.process_command(command)
                
            except KeyboardInterrupt:
                print("\nğŸ›‘ Ctrl+C ê°ì§€")
                break
            except Exception as e:
                print(f"âš ï¸ ì—ëŸ¬: {e}")
                time.sleep(0.5)
        
        print("\nğŸ‘‹ ì˜¤ë¦¬ì˜¨ C2 ì¢…ë£Œë¨")
        self.music_player.stop()


# --- [ì‹¤í–‰] ---
if __name__ == "__main__":
    if not os.path.exists(MUSIC_FOLDER):
        os.makedirs(MUSIC_FOLDER)
    
    orion = OrionPortable()
    orion.run()